{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형 공간 필터링 : 회선을 이용한 영상처리 방법\n",
    "\n",
    "비선형 공간 필터링 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.3.1 최대값/최소값 필터링\n",
    "최대값 필터링 : 마스크 계수 중 최대값을 통과시켜 출력 화소가 됨\n",
    "- 돌출되는 어두운 값이 제거, 전체적으로 밝은 영상이 됨\n",
    "- 밝은 임펄스 잡음이 강조\n",
    "\n",
    "최소값 필터링 : 마스크 계수 중 최소값을 통과시켜 출력 화소가 됨\n",
    "- 돌출되는 밝은 값이 제거, 전체적으로 어두운 영상이 됨\n",
    "- 어두운 임펄스 잡음이 강조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.3.1 최소값-최대값 필터링\n",
    "import numpy as np, cv2\n",
    "\n",
    "def minmax_filter(image, ksize, mode):\n",
    "    rows, cols = image.shape[:2]\n",
    "    dst = np.zeros((rows, cols), np.uint8)\n",
    "    center = ksize // 2\n",
    "\n",
    "    for i in range(center, rows - center):\n",
    "        for j in range(center, cols - center):\n",
    "            y1, y2 = i - center, i + center + 1\n",
    "            x1, x2 = j - center, j + center + 1\n",
    "            mask = image[y1:y2, x1:x2]\n",
    "            dst[i, j] = cv2.minMaxLoc(mask)[mode]\n",
    "    return dst\n",
    "\n",
    "image = cv2.imread(\"images_07/min_max.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "if image is None: raise Exception(\"영상 파일 읽기 오류\")\n",
    "\n",
    "minfilter_img = minmax_filter(image, 3, 0)\n",
    "maxfilter_img = minmax_filter(image, 3, 1)\n",
    "\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.imshow(\"minfilter_img\", minfilter_img)\n",
    "cv2.imshow(\"maxfilter_img\", maxfilter_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) :-1: error: (-5:Bad argument) in function 'blur'\n> Overload resolution failed:\n>  - Can't parse 'anchor'. Input argument doesn't provide sequence protocol\n>  - Can't parse 'anchor'. Input argument doesn't provide sequence protocol\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32md:\\github\\image-processing\\ch07\\07-3_기타_필터링.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github/image-processing/ch07/07-3_%EA%B8%B0%ED%83%80_%ED%95%84%ED%84%B0%EB%A7%81.ipynb#ch0000004?line=20'>21</a>\u001b[0m \u001b[39mif\u001b[39;00m image \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m영상 파일 읽기 오류\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github/image-processing/ch07/07-3_%EA%B8%B0%ED%83%80_%ED%95%84%ED%84%B0%EB%A7%81.ipynb#ch0000004?line=22'>23</a>\u001b[0m avg_img \u001b[39m=\u001b[39m average_filter(image, \u001b[39m5\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/github/image-processing/ch07/07-3_%EA%B8%B0%ED%83%80_%ED%95%84%ED%84%B0%EB%A7%81.ipynb#ch0000004?line=23'>24</a>\u001b[0m blur_img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mblur(image, (\u001b[39m5\u001b[39;49m,\u001b[39m5\u001b[39;49m), (\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), cv2\u001b[39m.\u001b[39;49mBORDER_REFLECT)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github/image-processing/ch07/07-3_%EA%B8%B0%ED%83%80_%ED%95%84%ED%84%B0%EB%A7%81.ipynb#ch0000004?line=24'>25</a>\u001b[0m box_img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mboxFilter(image, ddepth\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, ksize\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github/image-processing/ch07/07-3_%EA%B8%B0%ED%83%80_%ED%95%84%ED%84%B0%EB%A7%81.ipynb#ch0000004?line=26'>27</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m, image)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) :-1: error: (-5:Bad argument) in function 'blur'\n> Overload resolution failed:\n>  - Can't parse 'anchor'. Input argument doesn't provide sequence protocol\n>  - Can't parse 'anchor'. Input argument doesn't provide sequence protocol\n"
     ]
    }
   ],
   "source": [
    "# 7.3.2 평균값 필터링\n",
    "import numpy as np, cv2\n",
    "\n",
    "def average_filter(image, ksize):\n",
    "    rows, cols = image.shape[:2]\n",
    "    dst = np.zeros((rows, cols), np.uint8)\n",
    "    center = ksize // 2\n",
    "\n",
    "    for i in range(center, rows - center):\n",
    "        for j in range(center, cols - center):\n",
    "            y1, y2 = i - center, i + center + 1\n",
    "            x1, x2 = j - center, j + center + 1\n",
    "\n",
    "            if y1 < 0 or y2 > rows or x1 < 0 or x2 > cols: # 입력 범위값을 벗어난 경우\n",
    "                dst[i, j] = image[i, j]\n",
    "            else:\n",
    "                mask = image[y1:y2, x1:x2]\n",
    "                dst[i, j] = cv2.mean(mask)[0]\n",
    "    return dst\n",
    "\n",
    "image = cv2.imread(\"images_07/test.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "if image is None: raise Exception(\"영상 파일 읽기 오류\")\n",
    "\n",
    "avg_img = average_filter(image, 5)\n",
    "blur_img = cv2.blur(image, (5,5), (-1, -1), cv2.BORDER_REFLECT)\n",
    "box_img = cv2.boxFilter(image, ddepth=-1, ksize=(5,5))\n",
    "\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.imshow(\"avg_img\", avg_img)\n",
    "cv2.imshow(\"blur_img\", blur_img)\n",
    "cv2.imshow(\"box_img\", box_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.3.3 미디안 필터링\n",
    "import numpy as np, cv2\n",
    "\n",
    "def median_filter(image, ksize):\n",
    "    rows, cols = image.shape[:2]\n",
    "    dst = np.zeros((rows, cols), np.uint8)\n",
    "    center = ksize // 2\n",
    "\n",
    "    for i in range(center, rows - center):\n",
    "        for j in range(center, cols - center):\n",
    "            y1, y2 = i - center, i + center + 1\n",
    "            x1, x2 = j - center, j + center + 1\n",
    "            mask = image[y1:y2, x1:x2].flatten()\n",
    "\n",
    "            sort_mask = cv2.sort(mask, cv2.SORT_EVERY_COLUMN)\n",
    "            dst[i, j] = sort_mask[sort_mask.size//2]\n",
    "    return dst\n",
    "\n",
    "# 이미지에 강제로 노이즈를 만드는 함수\n",
    "def salt_pepper_noise(img, n):\n",
    "    h, w = img.shape[:2]\n",
    "    x, y = np.random.randint(0, w, n), np.random.randint(0, h, n)\n",
    "    noise = img.copy()\n",
    "    for (x, y) in zip(x, y):\n",
    "        noise[y, x] = 0 if np.random.rand() < 0.5 else 255\n",
    "    return noise\n",
    "\n",
    "image = cv2.imread(\"images_07/median2.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "if image is None: raise Exception(\"영상 파일 읽기 오류\")\n",
    "\n",
    "noise = salt_pepper_noise(image, 500) # 노이즈 이미지 생성\n",
    "med_img1 = median_filter(noise, 5)\n",
    "med_img2 = cv2.medianBlur(noise, 5)\n",
    "\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.imshow(\"noise\", noise)\n",
    "cv2.imshow(\"median\", med_img1)\n",
    "cv2.imshow(\"CV median\", med_img2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 가우시안 필터링\n",
    "\n",
    "정규 분포를 사용, 거리 대비로 나와 가까운 요소의 가중치를 높임\n",
    "\n",
    "멀리 있는 요소들까지 가져오더라도(고려하더라도) 이미지 손상이 다른 필터링에 비해서 덜함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.3.4 가우시안 필터링\n",
    "import numpy as np, cv2\n",
    "\n",
    "def getGaussianMask(ksize, sigmaX, sigmaY):\n",
    "    sigma = 0.3 * ((np.array(ksize) - 1.0) * 0.5 - 1.0) + 0.8\n",
    "    if sigmaX <= 0: sigmaX = sigma[0]\n",
    "    if sigmaY <= 0: sigmaY = sigma[1]\n",
    "\n",
    "    u = np.array(ksize)//2\n",
    "    x = np.arange(-u[0], u[0]+1, 1)\n",
    "    y = np.arange(-u[1], u[1]+1, 1)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "\n",
    "    ratio = 1 / (sigmaX * sigmaX * 2 * np.pi)\n",
    "    v1 = x ** 2 / (2 * sigmaX ** 2)\n",
    "    v2 = y ** 2 / (2 * sigmaY ** 2)\n",
    "    mask = ratio * np.exp(-(v1+v2))\n",
    "    return mask / np.sum(mask)\n",
    "\n",
    "image = cv2.imread(\"images_07/smoothing.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "if image is None: raise Exception(\"영상 파일 읽기 오류\")\n",
    "\n",
    "ksize = (17, 5)\n",
    "gaussian_2d = getGaussianMask(ksize, 0, 0)\n",
    "gaussian_1dX = cv2.getGaussianKernel(ksize[0], 0, cv2.CV_32F)\n",
    "gaussian_1dY = cv2.getGaussianKernel(ksize[1], 0, cv2.CV_32F)\n",
    "\n",
    "gauss_img1 = cv2.filter2D(image, -1, gaussian_2d)\n",
    "gauss_img2 = cv2.GaussianBlur(image, ksize, 0)\n",
    "gauss_img3 = cv2.sepFilter2D(image, -1, gaussian_1dX, gaussian_1dY)\n",
    "\n",
    "titles = ['image', 'gauss_img1', 'gauss_img2', 'gauss_img3']\n",
    "for t in titles: cv2.imshow(t, eval(t))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.3.5 블러링과 캐니 엣지를 이용한 컬러 엣지 검출\n",
    "import cv2\n",
    "\n",
    "def onTrackbar(th):\n",
    "    rep_edge = cv2.GaussianBlur(rep_gray, (5, 5), 0)\n",
    "    rep_edge = cv2.Canny(rep_edge, th, th*2, 5)\n",
    "    h, w = image.shape[:2]\n",
    "    cv2.rectangle(rep_edge, (0, 0, w, h), 255, -1)\n",
    "    color_edge = cv2.bitwise_and(rep_image, rep_image, mask=rep_edge)\n",
    "    cv2.imshow(\"color edge\", color_edge)\n",
    "\n",
    "image = cv2.imread(\"images_07/test.jpg\", cv2.IMREAD_COLOR)\n",
    "if image is None: raise Exception(\"영상 파일 읽기 오류\")\n",
    "\n",
    "th = 50\n",
    "rep_image = cv2.repeat(image, 1, 2)\n",
    "rep_gray = cv2.cvtColor(rep_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.namedWindow(\"color edge\", cv2.WINDOW_AUTOSIZE)\n",
    "cv2.createTrackbar(\"Canny th\", \"color edge\", th, 100, onTrackbar)\n",
    "onTrackbar(th)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee8e767f248e676331efd5b15066fe2f4c07a210f3df6062615d104073107a4a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
